# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Film/Acara TV Berbasis Konten

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Shmq2V7ANMOBoVvZBlPfDXcSrCqD8m3s

# **Bagian 1: Import Library**
"""

# Mengimpor library yang diperlukan untuk manipulasi data, analisis, dan pemodelan.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer # Untuk mengubah teks menjadi fitur numerik
from sklearn.metrics.pairwise import cosine_similarity       # Untuk menghitung kesamaan antar item
from wordcloud import WordCloud                              # Untuk visualisasi kata-kata paling sering muncul

# Mengatur tampilan plot agar lebih baik
plt.style.use('ggplot')

"""#**Bagian 2: Data Understanding (Pemahaman Data)**

## **Gathering Data**
"""

'''Langkah pertama adalah memuat data dan memahami struktur serta isinya. Kita akan memeriksa lima baris pertama, informasi kolom, nilai yang hilang, data duplikat, dan nilai unik untuk mendapatkan gambaran awal tentang dataset.'''
# 2.1 Gathering Data (Mengumpulkan Data)
df = pd.read_csv('/dataset/cleaned-movie_df.csv') # Contoh nama file dataset yang umum

# Melihat preview data (5 baris pertama)
print("\n--- Preview Data (df.head()) ---")
print(df.head())
print("\nUkuran DataFrame:", df.shape)

"""## **Assessing Data (Menilai Data)**"""

# 2.2.1 Checking Missing Values (Mengecek Nilai Kosong/Null)
print("\n--- Jumlah Nilai Kosong (df.isnull().sum()) ---")
print(df.isnull().sum())

# 2.2.2 Checking Duplicate Data (Mengecek Data Duplikat)
# Menghitung jumlah baris duplikat di seluruh DataFrame.
print("\n--- Jumlah Data Duplikat (df.duplicated().sum()) ---")
print(df.duplicated().sum())
'''Jika ada duplikat, kita mungkin perlu menghapusnya untuk memastikan keunikan data.'''

"""## **Exploratory Data Analysis (EDA) - Analisis Data Eksplorasi**

### **Unique Values (Nilai Unik)**
"""

# Mengecek jumlah nilai unik untuk kolom-kolom penting.
print("\n--- Jumlah Nilai Unik ---")
print(f"Jumlah Tipe Konten Unik (type): {df['type'].nunique()}")
print(f"Jumlah Judul Unik (title): {df['title'].nunique()}")
print(f"Jumlah Genre/Kategori Unik (listed_in): {df['listed_in'].nunique()}") # Perhatikan bahwa ini adalah string kombinasi genre

# Mengecek nilai unik untuk 'type'
print("\nDistribusi 'type':")
print(df['type'].value_counts())

# Mengecek nilai unique untuk 'listed_in' (genre/kategori)
'''Pertama, pisahkan string genre menjadi daftar genre individual'''
genres_split = df['listed_in'].str.split(', ', expand=True)
all_genres = genres_split.stack().unique()
print(f"\nJumlah Genre/Kategori Individual Unik (setelah pemisahan): {len(all_genres)}")
print("\nContoh Genre/Kategori Individual Unik:")
print(all_genres[:10]) # Menampilkan 10 contoh pertama

# Menghitung frekuensi setiap genre individual
genre_counts = genres_split.stack().value_counts()
print("\n--- 10 Genre/Kategori Paling Sering Muncul ---")
print(genre_counts.head(10))

# Visualisasi 10 genre/kategori teratas
plt.figure(figsize=(10, 6))
genre_counts.head(10).plot(kind='bar', color='skyblue')
plt.title('10 Kategori Konten Teratas (listed_in)')
plt.xlabel('Kategori')
plt.ylabel('Jumlah Kemunculan')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""### **Wordcloud**"""

# Fungsi untuk membuat wordcloud
def create_wordcloud(data, title):
    if data.empty:
        print(f"Tidak ada data untuk membuat wordcloud '{title}'.")
        return
    text = ' '.join(data.dropna().astype(str)) # Gabungkan semua teks, hilangkan NaN
    if not text:
        print(f"Teks kosong untuk membuat wordcloud '{title}'.")
        return
    wc = WordCloud(width=800, height=400, max_words=200, background_color='white').generate(text)
    plt.figure(figsize=(10, 8))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(title)
    plt.show()

# Wordcloud untuk 'listed_in' (genres)
create_wordcloud(df['listed_in'].str.replace(', ', ' ', regex=False), 'Wordcloud Kategori Konten')

"""# **Bagian 3: Data Preparation (Persiapan Data)**

Deskripsi:
Tahap ini fokus pada pembersihan dan transformasi data agar siap untuk pemodelan. Kita akan menangani nilai yang hilang, membersihkan teks, dan menggabungkan kolom yang relevan untuk membentuk fitur yang akan digunakan dalam Content-Based Filtering.

## **Penanganan Nilai Kosong**
"""

print("\n--- Jumlah Nilai Kosong Setelah Penanganan (df.isnull().sum()) ---")
print(df.isnull().sum())

"""## **Penanganan Data Duplikat**"""

# Membersihkan duplikat berdasarkan 'title' dan 'type', hapus.
'''Ini penting untuk memastikan setiap film/acara TV unik.'''
df.drop_duplicates(subset=['title', 'type'], inplace=True)
print(f"\nJumlah baris setelah menghapus duplikat: {df.shape[0]}")

"""## **Membersihkan Teks dan Menggabungkan Fitur**"""

'''Kita akan menggabungkan beberapa kolom teks menjadi satu kolom 'features' untuk TF-IDF Vectorizer. Kolom yang relevan adalah:'title', 'director', 'cast', 'listed_in' (genre), 'description'.'''

# Bersihkan kolom 'listed_in' agar sesuai untuk TF-IDF
# Ganti koma dan spasi dengan satu spasi untuk memisahkan genre
df['listed_in'] = df['listed_in'].str.replace(', ', ' ', regex=False)

# Gabungkan semua fitur teks menjadi satu kolom 'combined_features'
# Mengubah semua menjadi huruf kecil untuk konsistensi
df['combined_features'] = (
    df['title'].str.lower() + ' ' +
    df['listed_in'].str.lower() + ' ' )

# Menghapus karakter khusus dari kolom 'combined_features'
# Ini membantu membersihkan teks dari simbol-simbol yang tidak relevan.
df['combined_features'] = df['combined_features'].str.replace(r'[^a-zA-Z0-9\s]', '', regex=True).str.strip()

print("\n--- Contoh Kolom 'combined_features' (5 baris pertama) ---")
print(df[['title', 'combined_features']].head())

"""## **Feature Extraction (Ekstraksi Fitur) dengan TF-IDF**"""

'''TF-IDF Vectorizer akan mengubah teks menjadi representasi numerik. Stop_words='english' akan menghapus kata-kata umum seperti 'the', 'is', 'and'.
max_features membatasi jumlah kata unik yang akan digunakan untuk mengurangi dimensi.'''
tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)

# Latih (fit) TF-IDF Vectorizer pada kolom 'combined_features' dan transformasikan teks.
'''Outputnya adalah sparse matrix.'''
tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined_features'])

print(f"\nBentuk Matriks TF-IDF: {tfidf_matrix.shape}")
print(f"Tipe Matriks TF-IDF: {type(tfidf_matrix)}")

"""## **Menghitung Kesamaan Cosine (Cosine Similarity)**"""

'''Cosine Similarity mengukur kesamaan arah antara dua vektor. Semakin tinggi nilai cosine similarity (mendekati 1), semakin mirip kedua item.'''
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print(f"\nBentuk Matriks Cosine Similarity: {cosine_sim.shape}")
# Matriks ini akan memiliki ukuran (jumlah_konten x jumlah_konten)

"""# **Bagian 4: Model Development (Pengembangan Model) - Content-Based Filtering**

Deskripsi:
Kita akan membuat fungsi yang menggunakan matriks kesamaan cosine untuk merekomendasikan film/acara TV yang mirip dengan input yang diberikan.
"""

# Fungsi untuk rekomendasi film/acara TV berdasarkan Content-Based Filtering
def recommend_content_based(title, df, cosine_sim):
    """
    Merekomendasikan film/acara TV yang mirip berdasarkan Content-Based Filtering.

    Args:
        title (str): Judul film/acara TV yang menjadi referensi.
        df (pd.DataFrame): DataFrame yang berisi data film/acara TV.
        cosine_sim (numpy.ndarray): Matriks cosine similarity.

    Returns:
        pd.DataFrame: DataFrame berisi rekomendasi film/acara TV yang mirip.
    """
    # Mencari indeks judul film/acara TV yang menjadi referensi
    # Menggunakan 'title' setelah pembersihan (lowercase)
    title_lower = title.lower()
    # Pastikan judul yang dicari ada di DataFrame
    if title_lower not in df['title'].str.lower().values:
        print(f"Judul '{title}' tidak ditemukan dalam dataset. Mohon periksa kembali judulnya.")
        return pd.DataFrame() # Mengembalikan DataFrame kosong jika judul tidak ditemukan

    idx = df[df['title'].str.lower() == title_lower].index[0]

    # Dapatkan skor kesamaan dari film/acara TV referensi dengan semua film/acara TV lainnya
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Urutkan film/acara TV berdasarkan skor kesamaan secara menurun
    # sim_scores adalah list of tuples (indeks, skor_kesamaan)
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Dapatkan skor dari 10 film/acara TV teratas yang paling mirip (kecuali dirinya sendiri)
    # sim_scores[0] adalah film itu sendiri, jadi kita mulai dari indeks 1
    sim_scores = sim_scores[1:11]

    # Dapatkan indeks film/acara TV dari rekomendasi teratas
    movie_indices = [i[0] for i in sim_scores]

    # Kembalikan DataFrame berisi judul, tipe, dan kategori dari film/acara TV yang direkomendasikan
    return df.iloc[movie_indices][['title', 'type', 'listed_in']]

"""# **Bagian 5: Contoh Penggunaan dan Konseptual Evaluasi Model**"""

# Contoh rekomendasi untuk 'Stranger Things'
print("\n--- Rekomendasi Mirip 'Stranger Things' ---")
recommendations_stranger_things = recommend_content_based('Stranger Things', df, cosine_sim)
if not recommendations_stranger_things.empty:
    print(recommendations_stranger_things)

# Contoh rekomendasi untuk 'Die Hard'
print("\n--- Rekomendasi Mirip 'Money Heist' ---")
recommendations_die_hard = recommend_content_based('Money Heist: The Phenomenon', df, cosine_sim)
if not recommendations_die_hard.empty:
    print(recommendations_die_hard)

# Contoh rekomendasi untuk 'Toy Story'
print("\n--- Rekomendasi Mirip 'Toy Story' ---")
recommendations_toy_story = recommend_content_based('Toy Story', df, cosine_sim)
if not recommendations_toy_story.empty:
    print(recommendations_toy_story)